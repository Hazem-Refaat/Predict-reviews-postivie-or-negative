{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-01T12:52:20.315599Z","iopub.status.busy":"2023-07-01T12:52:20.315074Z","iopub.status.idle":"2023-07-01T12:52:20.331891Z","shell.execute_reply":"2023-07-01T12:52:20.330699Z","shell.execute_reply.started":"2023-07-01T12:52:20.315556Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:52:20.335528Z","iopub.status.busy":"2023-07-01T12:52:20.334681Z","iopub.status.idle":"2023-07-01T12:52:21.187515Z","shell.execute_reply":"2023-07-01T12:52:21.186273Z","shell.execute_reply.started":"2023-07-01T12:52:20.335485Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(50000, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Probably my all-time favorite movie, a story o...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>I sure would like to see a resurrection of a u...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>This show was an amazing, fresh &amp; innovative i...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Encouraged by the positive comments about this...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>If you like original gut wrenching laughter yo...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n","5  Probably my all-time favorite movie, a story o...  positive\n","6  I sure would like to see a resurrection of a u...  positive\n","7  This show was an amazing, fresh & innovative i...  negative\n","8  Encouraged by the positive comments about this...  negative\n","9  If you like original gut wrenching laughter yo...  positive"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#importing the training data\n","imdb_data=pd.read_csv('E:/Projects/IMDB project/IMDB Dataset.csv/IMDB Dataset.csv')\n","print(imdb_data.shape)\n","imdb_data.head(10)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:52:21.190278Z","iopub.status.busy":"2023-07-01T12:52:21.189510Z","iopub.status.idle":"2023-07-01T12:52:21.322816Z","shell.execute_reply":"2023-07-01T12:52:21.321606Z","shell.execute_reply.started":"2023-07-01T12:52:21.190234Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>50000</td>\n","      <td>50000</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>49582</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Loved today's show!!! It was a variety and not...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>5</td>\n","      <td>25000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   review sentiment\n","count                                               50000     50000\n","unique                                              49582         2\n","top     Loved today's show!!! It was a variety and not...  positive\n","freq                                                    5     25000"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["imdb_data.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Remove HTML tags"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:52:21.327278Z","iopub.status.busy":"2023-07-01T12:52:21.326524Z","iopub.status.idle":"2023-07-01T12:52:21.336351Z","shell.execute_reply":"2023-07-01T12:52:21.334924Z","shell.execute_reply.started":"2023-07-01T12:52:21.327235Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["This is an example text with HTML tags.\n"]}],"source":["import re\n","from bs4 import BeautifulSoup\n","\n","def remove_html_tags(text): #remove HTML tags\n","    soup = BeautifulSoup(text, \"html.parser\")\n","    clean_text = soup.get_text()\n","    return clean_text\n","\n","text = \"<p>This is an <b>example</b> text with HTML tags.</p>\"\n","clean_text = remove_html_tags(text)\n","print(clean_text)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Remove Punctuation\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:52:21.338670Z","iopub.status.busy":"2023-07-01T12:52:21.338238Z","iopub.status.idle":"2023-07-01T12:52:21.352457Z","shell.execute_reply":"2023-07-01T12:52:21.350878Z","shell.execute_reply.started":"2023-07-01T12:52:21.338632Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Hello This is an example sentence\n"]}],"source":["import string\n","\n","def remove_punctuation(text):\n","    clean_text = \"\".join([char for char in text if char not in string.punctuation])\n","    return clean_text\n","\n","text = \"Hello! This is an example sentence.\"\n","clean_text = remove_punctuation(text)\n","print(clean_text)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Remove Special Characters"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:52:21.355750Z","iopub.status.busy":"2023-07-01T12:52:21.354913Z","iopub.status.idle":"2023-07-01T12:52:21.365180Z","shell.execute_reply":"2023-07-01T12:52:21.363883Z","shell.execute_reply.started":"2023-07-01T12:52:21.355707Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Hello This is an example sentence\n"]}],"source":["import re\n","\n","def remove_special_characters(text):\n","    clean_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n","    return clean_text\n","\n","text = \"Hello! This is @an example #sentence.\"\n","clean_text = remove_special_characters(text)\n","print(clean_text)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Normalize Text\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:52:21.368258Z","iopub.status.busy":"2023-07-01T12:52:21.367428Z","iopub.status.idle":"2023-07-01T12:52:21.375657Z","shell.execute_reply":"2023-07-01T12:52:21.374413Z","shell.execute_reply.started":"2023-07-01T12:52:21.368216Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["hello! this is an example sentence.\n"]}],"source":["def normalize_text(text):\n","    clean_text = text.lower()\n","    return clean_text\n","\n","text = \"Hello! This is an EXAMPLE sentence.\"\n","clean_text = normalize_text(text)\n","print(clean_text)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Handle Contractions"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:52:34.925424Z","iopub.status.busy":"2023-07-01T12:52:34.925017Z","iopub.status.idle":"2023-07-01T12:52:34.932655Z","shell.execute_reply":"2023-07-01T12:52:34.931645Z","shell.execute_reply.started":"2023-07-01T12:52:34.925385Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["I cannot believe it!\n"]}],"source":["import contractions\n","\n","def expand_contractions(text):\n","    expanded_text = contractions.fix(text)\n","    return expanded_text\n","\n","text = \"I can't believe it!\"\n","expanded_text = expand_contractions(text)\n","print(expanded_text)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Remove Stop Words\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:52:34.938383Z","iopub.status.busy":"2023-07-01T12:52:34.937894Z","iopub.status.idle":"2023-07-01T12:52:34.951812Z","shell.execute_reply":"2023-07-01T12:52:34.950620Z","shell.execute_reply.started":"2023-07-01T12:52:34.938333Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["example sentence stop words.\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\hazem\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.corpus import stopwords\n","\n","nltk.download('stopwords')\n","\n","def remove_stopwords(text):\n","    stop_words = set(stopwords.words('english'))\n","    tokens = text.split()\n","    clean_tokens = [token for token in tokens if token.lower() not in stop_words]\n","    clean_text = \" \".join(clean_tokens)\n","    return clean_text\n","\n","text = \"This is an example sentence with some stop words.\"\n","clean_text = remove_stopwords(text)\n","print(clean_text)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Remove Numbers"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:52:34.954482Z","iopub.status.busy":"2023-07-01T12:52:34.953995Z","iopub.status.idle":"2023-07-01T12:52:34.964919Z","shell.execute_reply":"2023-07-01T12:52:34.963841Z","shell.execute_reply.started":"2023-07-01T12:52:34.954441Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["This is an example sentence with  numbers.\n"]}],"source":["def remove_numbers(text):\n","    clean_text = re.sub(r\"\\d+\", \"\", text)\n","    return clean_text\n","\n","text = \"This is an example sentence with 123 numbers.\"\n","clean_text = remove_numbers(text)\n","print(clean_text)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Remove Extra Whitespace"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:52:34.966881Z","iopub.status.busy":"2023-07-01T12:52:34.966551Z","iopub.status.idle":"2023-07-01T12:52:34.977332Z","shell.execute_reply":"2023-07-01T12:52:34.976113Z","shell.execute_reply.started":"2023-07-01T12:52:34.966853Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["This is an example sentence.\n"]}],"source":["def remove_extra_whitespace(text):\n","    clean_text = \" \".join(text.split())\n","    return clean_text\n","\n","text = \"   This    is   an   example   sentence.   \"\n","clean_text = remove_extra_whitespace(text)\n","print(clean_text)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["imdb_data.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\hazem\\AppData\\Local\\Temp\\ipykernel_22584\\3455125503.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  soup = BeautifulSoup(text, \"html.parser\")\n"]}],"source":["def preprocess_text(text):\n","\n","    text = remove_html_tags(text)\n","    text = remove_punctuation(text)\n","    text = remove_special_characters(text)\n","    text = normalize_text(text)\n","    text = expand_contractions(text)\n","    text = remove_stopwords(text)\n","    text = remove_numbers(text)\n","    text = remove_extra_whitespace(text)\n","\n","    return text\n","\n","imdb_data['clean_text'] = imdb_data['review'].apply(preprocess_text)\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                              review sentiment  \\\n","0  One of the other reviewers has mentioned that ...  positive   \n","1  A wonderful little production. <br /><br />The...  positive   \n","2  I thought this was a wonderful way to spend ti...  positive   \n","3  Basically there's a family where a little boy ...  negative   \n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n","\n","                                          clean_text  \n","0  one reviewers mentioned watching oz episode ho...  \n","1  wonderful little production filming technique ...  \n","2  thought wonderful way spend time hot summer we...  \n","3  basically family little boy jake thinks zombie...  \n","4  petter matteis love time money visually stunni...  \n"]}],"source":["# Display the updated DataFrame\n","print(imdb_data.head())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Tokenize clean_text"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\hazem\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["0        [one, reviewers, mentioned, watching, oz, epis...\n","1        [wonderful, little, production, filming, techn...\n","2        [thought, wonderful, way, spend, time, hot, su...\n","3        [basically, family, little, boy, jake, thinks,...\n","4        [petter, matteis, love, time, money, visually,...\n","                               ...                        \n","49995    [thought, movie, right, good, job, creative, o...\n","49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n","49997    [catholic, taught, parochial, elementary, scho...\n","49998    [going, disagree, previous, comment, side, mal...\n","49999    [one, expects, star, trek, movies, high, art, ...\n","Name: tokens, Length: 50000, dtype: object\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","def tokenize(text):\n","    preprocessed_text = preprocess_text(text)\n","    tokens = word_tokenize(preprocessed_text)\n","    return tokens\n","imdb_data['tokens'] = imdb_data['clean_text'].apply(tokenize)\n","print(imdb_data['tokens'])\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Create word-to-index mapping\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(imdb_data['tokens'])\n","\n","# Conver text to sequences\n","sequences = tokenizer.texts_to_sequences(imdb_data['tokens'])\n","\n","#pad sequences\n","\n","max_seq_length = 100\n","padded_sequences = pad_sequences(sequences, maxlen=max_seq_length)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Split into input and target\n","X = padded_sequences\n","labels = imdb_data['sentiment']\n","y = labels\n","\n","# Step 2: Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","label_encoder = LabelEncoder()\n","y_train = label_encoder.fit_transform(y_train)\n","y_test= label_encoder.transform(y_test)\n","# Define the RNN model architecture\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 100\n","max_length = 100"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Step 3: Define the RNN model architecture\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n","model.add(LSTM(units=128))\n","model.add(Dense(units=1, activation='sigmoid'))\n","\n","# Step 4: Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","1250/1250 [==============================] - 29s 19ms/step - loss: 0.3495 - accuracy: 0.8509\n","Epoch 2/10\n","1250/1250 [==============================] - 23s 19ms/step - loss: 0.1405 - accuracy: 0.9492\n","Epoch 3/10\n","1250/1250 [==============================] - 23s 19ms/step - loss: 0.0574 - accuracy: 0.9805\n","Epoch 4/10\n","1250/1250 [==============================] - 23s 18ms/step - loss: 0.0315 - accuracy: 0.9901\n","Epoch 5/10\n","1250/1250 [==============================] - 23s 19ms/step - loss: 0.0242 - accuracy: 0.9921\n","Epoch 6/10\n","1250/1250 [==============================] - 23s 19ms/step - loss: 0.0133 - accuracy: 0.9955\n","Epoch 7/10\n","1250/1250 [==============================] - 24s 19ms/step - loss: 0.0133 - accuracy: 0.9961\n","Epoch 8/10\n","1250/1250 [==============================] - 24s 19ms/step - loss: 0.0055 - accuracy: 0.9984\n","Epoch 9/10\n","1250/1250 [==============================] - 23s 19ms/step - loss: 0.0072 - accuracy: 0.9975\n","Epoch 10/10\n","1250/1250 [==============================] - 22s 18ms/step - loss: 0.0056 - accuracy: 0.9979\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7722 - accuracy: 0.8600\n","Test Loss: 0.7721770405769348\n","Test Accuracy: 0.8600000143051147\n"]}],"source":["# Step 5: Train the model\n","model.fit(X_train, y_train, epochs=10, batch_size=32)\n","\n","# Step 6: Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print('Test Loss:', loss)\n","print('Test Accuracy:', accuracy)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Predict new reviews"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["extremely satisfied product exceeded expectations every aspect build quality superb functions flawlessly customer service provided company exceptional quick response times friendly approach item delivered time perfect condition made life much easier enjoyable highly recommend product anyone need reliable efficient solution\n","Predicted sentiment: positive\n","Confidence: [0.9999602]\n"]}],"source":["# Preprocess the new text\n","new_text = \"I am extremely satisfied with this product. It has exceeded my expectations in every aspect. The build quality is superb, and it functions flawlessly. The customer service provided by the company was exceptional, with quick response times and a friendly approach. The item was delivered on time and in perfect condition. It has made my life so much easier and more enjoyable. I highly recommend this product to anyone in need of a reliable and efficient solution.\"\n","preprocessed_text = preprocess_text(new_text)\n","\n","# Tokenize the preprocessed text\n","tokens = tokenizer.texts_to_sequences([preprocessed_text])\n","print(preprocessed_text)\n","# Pad the tokenized sequence\n","padded_sequence = pad_sequences(tokens, maxlen=max_length)\n","\n","# Make predictions\n","predictions = model.predict(padded_sequence)\n","\n","# Interpret the predictions\n","sentiment = \"positive\" if predictions[0] > 0.5 else \"negative\"\n","confidence = predictions[0] if predictions[0] > 0.5 else 1 - predictions[0]\n","\n","# Print the result\n","print(\"Predicted sentiment:\", sentiment)\n","print(\"Confidence:\", confidence)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
